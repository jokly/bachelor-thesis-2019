Во время анализа структуры данных и различных моделей рекомендательных систем было
принято решение о реализации двух подходов: рекомендовать пользователю компании и
блюда, основываясь на его истории заказов; рекомендовать пользователю следующий
товар в его корзину.

\subsubsection{Коллаборативная фильтрация}

Для формальной постановки задачи необходимо ввести некоторые обозначения. Возьмем
множество пользователей за $\mathcal{U}$, множество товаров за $\mathcal{I}$, а
множество оценок за $\mathcal{R}$ (множество возможных значений оценок
определяется как $\mathcal{S}$, например $\mathcal{S}=[1,5]$ или
$\mathcal{S}=\{like, dislike\}$).Предполагается, что пользователь $u \in \mathcal{U}$
может поставить не более одной оценки любому элементу $i \in \mathcal{I}$,
обозначим этот факт, как $r_{ui}$. Для определения подмножества
пользователей, которые оценили товар $i$ используем обозначение $\mathcal{U}_i$.
Аналогично, $\mathcal{I}_u$ представляет подмножество товаров, которые были оценены
пользователем $u$. Также, важной частью дальнейших
рассуждений являются товары, которые оценили два пользователя $u$
и $v$, т.е. $\mathcal{I}_u \cap \mathcal{I}_v$, для этого определения
используем $\mathcal{I}_{uv}$. Таким же образом $\mathcal{U}_{ij}$ используется,
чтобы определить множество пользователей, которые оценили оба товара $i$ и $j$.

Перед рекомендательными системами ставится много задач, одними из них являются:
нахождение лучшего товара и нахождение списка наилучших товаров для пользователя.
Первая проблема заключается в нахождении нового элемента $i \in \mathcal{I} \setminus \mathcal{I}_u$,
который был бы самым интересным для пользователя $u$. Когда известны явные оценки
пользователей о товарах (implicit feedback), чаще всего задача определяется как
регрессионная и ставится задача в обучении функции $f: \mathcal{U} \times \mathcal{I} \to \mathcal{S}$,
которая предсказывает оценки $f(u, i)$ пользователя $u$ для "нового" предмета $i$.
Эта функция в дальнейшем используется для рекомендации активному пользователю $u_a$
товар $i^*$, для которого предсказываемый рейтинг имеет наибольшее значение:
\begin{equation}
  i^* = \arg \max_{j \in \mathcal{I} \setminus \mathcal{I}_u} f(u_a,j)
\end{equation}
\label{metrics} Чаще всего для определения качества таких рекомендаций оценивается точность предсказания
оценок. Для этого множество $\mathcal{R}$ делят на обучающую выборку $\mathcal{R}_{train}$,
используемую для обучению и тестовую $\mathcal{R}_{test}$, для вычисления точности
предсказаний. Существует две популярные метрики: средняя абсолютная ошибка (\ref{cf_mae}) и
среднеквадратическое отклонение (\ref{cf_rmse}).
\begin{equation}
  \label{cf_mae}
  MAE(f) = \frac{1}{|\mathcal{R}_{test}|} \sum_{r_{ui} \in \mathcal{R}_{test}} |f(u,i) - r_{ui}|
\end{equation}
\begin{equation}
  \label{cf_rmse}
  RMSE(f) = \sqrt{\frac{1}{|\mathcal{R}_{test}|} \sum_{r_{ui} \in \mathcal{R}_{test}} (f(u,i) - r_{ui})^2}
\end{equation}
Когда рейтинги не предоставлены, например, если известен только список покупок,
сделанных каждым пользователем, вычисление точности прогноза рейтинга невозможно.
В этом случае проблема нахождения наилучшего товара обычно приводится к задаче
рекомендации пользователю $u_a$ списка $L(u_a)$, содержащего $N$ наиболее интересных
товаров для него. Таким образом, качество рекомендаций может быть рассчитано путем
деления множества $\mathcal{I}$ на подмножество $\mathcal{I}_{train}$, используемое
для обучения $L$, и подмножества для тестирования $\mathcal{I}_{test}$. Возьмем
$T(u) \subset \mathcal{I}_u \cap \mathcal{I}_{test}$ за подмножество товаров, которые
являются релевантными для пользователя $u$. Точность такого метода затем можно
вычислить при помощи следующих метрик: точности (\ref{cf_precision}) и
полноты (\ref{cf_recall}).
\begin{equation}
  \label{cf_precision}
  Precision(L) = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} |L(u) \cap T(u)| / |L(u)|
\end{equation}
\begin{equation}
  \label{cf_recall}
  Recall(L) = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} |L(u) \cap T(u)| / |T(u)|
\end{equation}

\textbf{Item-based}

Коллаборативная фильтрация разделяется на два основных подхода: user-based и item-based.
В этом параграфе мы рассмотрим второй из них. Для этого положим, что для каждого
товара $i \neq j$ значение $w_{ij}$ отражает их сходство.
Обозначим за $\mathcal{N}_u(i)$ - множество товаров наиболее похожих на $i$, которые
оценил пользователь $u$. Таким образом, мы можем рассчитать прогнозируемый рейтинг:
\begin{equation}
  \hat{r}_{ui} = \frac{\sum_{j \in \mathcal{N}_u(i)} w_{ij}r_{uj}}{\sum_{j \in \mathcal{N}_u(i)} |w_{ij}|}
\end{equation}

Для расчета значений $w_{ij}$ существуют такие меры сходства, как:
\begin{enumerate}
  \label{mesure}
  \item Коэффициент Жаккара
  \begin{equation}
    \label{mesure_js}
    JS(i,j) = \frac{|U_i \cap U_j|}{|U_i \cup U_j|}
  \end{equation}
  \item Косинусное сходство
  \begin{equation}
    \label{mesure_cs}
    CS(i,j) = \frac{\sum_{u \in U_{ij}} r_{ui}r_{uj}}{\sqrt{\sum_{u \in U_{ij}} r_{ui}^2}\sqrt{\sum_{u \in U_{ij}} r_{uj}^2}}
  \end{equation}
  \item Коэффициент корреляции Пирсона
  \begin{equation}
    \label{mesure_ps}
    PS(i,j) = \frac
      {\sum_{u \in U_{ij}} (r_{ui} - \hat{r}_i)(r_{uj} - \hat{r}_j)}
      {\sqrt{\sum_{u \in U_{ij}} (r_{ui} - \hat{r}_i)^2}\sqrt{\sum_{u \in U_{ij}} (r_{uj} - \hat{r}_j)^2}}
  \end{equation}
\end{enumerate}
Также, в зависимости от выбранной меры, применяются различные способы вычисления
предсказания предмета:
\begin{enumerate}
  \item В случае, когда оценки не представлены
  \begin{equation}
    \hat{r}_{uj} = \frac{\sum_{i \in I_u} w_{ij}}{|I_u|}
  \end{equation}
  \item Для коэффициента Жаккара (\ref{mesure_js}) и косинусового сходства (\ref{mesure_cs})
  \begin{equation}
    \hat{r}_{uj} = \frac{\sum_{i \in I_u} w_{ij} r_{ui} }{\sum_{i \in I_u} w_{ij}}
  \end{equation}
  \item Для коэффициента корреляции Пирсона
  \begin{equation}
    \hat{r}_{uj} = \bar{r}_j + \frac{\sum_{i \in I_u} w_{ij} (r_{ui} - \bar{r}_i) }{\sum_{i \in I_u} w_{ij}}
  \end{equation}

\end{enumerate}

\subsubsection{Модели классификации}
В процессе обсуждения способов рекомендаций был предложен следующий метод: рекомендовать
пользователю на основе уже добавленных блюд в корзину следующее. Для этого данные о заказах были
представлены в формате, представленном в таблице \ref{table:1} (где $id_i$ - ID блюда).
Значения в столбцах $id_i$ отражают факт присутствия блюда в корзине, а значение в
столбце $Y$ - ID блюда, которое пользователь добавил следующим.
\begin{table}[H]
  \centering
  \begin{tabular} { | c | c | c | c | c | }
  \hline
  $id_1$ & $id_2$ & ... & $id_n$ & Y \\
  \hline
  True  & True  & ... & False & $id_x$ \\
  \hline
  ...  & ...  & ... & ... & ... \\
  \hline
  True  & False  & ... & True & $id_y$ \\
  \hline
  \end{tabular}
  \caption{Датасет для классификации}
  \label{table:1}
\end{table}
Для создания большого объема обучающей выборки в каждом заказе поочередно исключалось
одно блюдо, которое становилось значением в столбце $Y$. Для решения поставленной
задачи был выбраны следующие модели:
\begin{itemize}
  \item Bernoulli Naive Bayes \cite{BernoulliNB}
  \item Random Forest \cite{RandomForest}
  \item Stochastic Gradient Descent \cite{SGD}
  \item XGBoosting \cite{XGBoosting}
\end{itemize}
